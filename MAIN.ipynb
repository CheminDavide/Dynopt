{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9496f57f",
   "metadata": {},
   "source": [
    "# Dynamic optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b6d588",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b0edb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "no path specified",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m root \u001b[38;5;241m=\u001b[39m tk\u001b[38;5;241m.\u001b[39mTk()\n\u001b[1;32m     30\u001b[0m root\u001b[38;5;241m.\u001b[39mwithdraw()\n\u001b[0;32m---> 31\u001b[0m source_path \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiledialog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maskopenfilename\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m source_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(source_path)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     33\u001b[0m REF_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_vids/tempRAW_refs/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m#raw files for each shot\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/posixpath.py:453\u001b[0m, in \u001b[0;36mrelpath\u001b[0;34m(path, start)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m\"\"\"Return a relative version of a path\"\"\"\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path:\n\u001b[0;32m--> 453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno path specified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    455\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(path)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mbytes\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: no path specified"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os #to access system folders\n",
    "import subprocess #to access ffmpeg in the system\n",
    "import shutil #to remove directories\n",
    "import numpy as np #easy vector operations\n",
    "import math #for operation with infinite\n",
    "import itertools\n",
    "from scipy.optimize import curve_fit #fittin of the curve\n",
    "import json #to handle json files\n",
    "import matplotlib.pyplot as pl #to display plots\n",
    "import tkinter as tk #to import file\n",
    "from tkinter import filedialog #to open import dialog\n",
    "\n",
    "#constants\n",
    "PARAM_AVC = {\"crfs\": 52, \"starting_range\": [0,51], \"lib\": \"libx264\", \"container\": \"mp4\", \"add_param\": \"\"}\n",
    "PARAM_HEVC = {\"crfs\": 52, \"starting_range\": [15,46], \"lib\": \"libx265\", \"container\": \"mp4\", \"add_param\": \"\"}\n",
    "PARAM_VP9 = {\"crfs\": 64, \"starting_range\": [15,51], \"lib\": \"libvpx-vp9\", \"container\": \"webm\", \"add_param\": \"-b:v 0\"}\n",
    "\n",
    "#variables - CUSTOM\n",
    "codec = \"avc\" #values: \"avc\", \"hevc\", \"vp9\", !!not implemented: \"av1\", \"vvc\"\n",
    "raw_width = 480\n",
    "raw_height = 270\n",
    "raw_fps = 29.97\n",
    "#values \"rate\",\"vmaf\", \"psnr\" !!not implemented: \"ssim\", \"mssim\"\n",
    "target_list = {\"vmaf\": [75], \"rate\": []}\n",
    "opt_tech = \"tg\" #fs = full search, tg = target tune, lg = pure lagrange !!not implemented\n",
    "\n",
    "#input file\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "source_path = os.path.relpath(filedialog.askopenfilename())\n",
    "source_name = os.path.basename(source_path).split('.')[0]\n",
    "REF_PATH = \"test_vids/tempRAW_refs/\" #raw files for each shot\n",
    "[os.remove(REF_PATH+f) for f in os.listdir(REF_PATH)] #clean temp_refs folder\n",
    "DIST_PATH = \"test_vids/temp_encoded/\" #encoded files for each shot\n",
    "[shutil.rmtree(DIST_PATH+f) for f in os.listdir(DIST_PATH)] #clean temp_encoded folder\n",
    "\n",
    "#assessment files path\n",
    "tm_file = \"rd_results/template.json\"\n",
    "rd_file = \"rd_results/\" + source_name + \".json\"\n",
    "if not os.path.isfile(rd_file): #if file does not exists create it\n",
    "    with open(rd_file, 'w') as f:\n",
    "        pass\n",
    "VMAF_LOGS = \"rd_results/vmaf_logs.json\"\n",
    "\n",
    "#shot detection\n",
    "TIME_LOGS = \"shot_detection.log\"\n",
    "shot_th = 0.25 #change shot threshold\n",
    "num_scenes = 0\n",
    "duration = 0.0\n",
    "\n",
    "#output file\n",
    "OUT_LIST = \"shot_list.txt\"\n",
    "OUT_PATH = \"test_vids/OPT_vids/\"\n",
    "\n",
    "#all computed points, by row: crf, bitrate, vmaf, psnr\n",
    "str_matrix = {\"crf\": None, \"bitrate\": None, \"vmaf\": None, \"psnr\": None}\n",
    "\n",
    "print(\"init done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1949a36",
   "metadata": {},
   "source": [
    "## Shot change detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d49c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#an empty json structure is generated to be filled and to store computed values\n",
    "def init_res_matrix(x):\n",
    "    str_matrix[\"crf\"] = np.zeros(x, dtype=int).tolist()\n",
    "    str_matrix[\"rate\"] = np.zeros(x, dtype=int).tolist()\n",
    "    str_matrix[\"vmaf\"] = np.zeros(x).tolist()\n",
    "    str_matrix[\"psnr\"] = np.zeros(x).tolist()\n",
    "    \n",
    "#detect shot changes in the scene and split it into shots\n",
    "def shot_change_detection(p):\n",
    "    start_t = 0.0\n",
    "    end_t = 0.0\n",
    "    global duration\n",
    "    #return when the shot changes\n",
    "    det = f\"ffmpeg -i {p} -filter_complex:v \\\"select='gt(scene,{shot_th})', \\\n",
    "        metadata=print:file={TIME_LOGS}\\\" -f null -\"\n",
    "    subprocess.call(det, shell=True)\n",
    "    #get the total duration for the last cut\n",
    "    idu = f\"ffprobe -v error -select_streams v:0 -show_entries format:stream -print_format json {p}\"\n",
    "    dta = json.loads(subprocess.run(idu.split(), stdout=subprocess.PIPE, stderr=subprocess.STDOUT).stdout)\n",
    "    duration = float(dta['format']['duration'])\n",
    "    \n",
    "    with open(\"shot_detection.log\", 'r') as r:\n",
    "        tm_log = r.read().splitlines()[::2]\n",
    "    tm_log.append(\"end pts_time:\" + str(duration))\n",
    "    n = len(tm_log)\n",
    "    for i,l in enumerate(tm_log): #for each cut\n",
    "        #create a folder for each scene\n",
    "        new_dir = str(i)\n",
    "        new_path = os.path.join(DIST_PATH, new_dir)\n",
    "        os.mkdir(new_path)\n",
    "        \n",
    "        #cut the video\n",
    "        end_t = l.split(\"pts_time:\",1)[1]\n",
    "        cut = f\"ffmpeg -ss {start_t} -to {end_t} -i {p} \\\n",
    "            -pix_fmt yuv420p {REF_PATH}scene{str(i).zfill(7)}.yuv\"\n",
    "        subprocess.call(cut, shell=True)\n",
    "        start_t = end_t\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b023a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_points = [] #structure of target points for the json file\n",
    "struct_shots = [] #structure of shots for the json file\n",
    "\n",
    "if source_path.endswith(\".yuv\"):\n",
    "    print(\"yuv input\")\n",
    "elif source_path.endswith(\".y4m\"):\n",
    "    print(\"y4m input\")\n",
    "else:\n",
    "    print(\"No such an input type\")\n",
    "    exit()\n",
    "\n",
    "num_scenes = shot_change_detection(source_path)\n",
    "    \n",
    "#init values based on the selected output codec\n",
    "if codec == \"avc\":\n",
    "    s_cod = PARAM_AVC\n",
    "    init_res_matrix(PARAM_AVC[\"crfs\"])\n",
    "elif codec == \"hevc\":\n",
    "    s_cod = PARAM_HEVC\n",
    "    init_res_matrix(PARAM_HEVC[\"crfs\"])\n",
    "elif codec == \"vp9\":\n",
    "    s_cod = PARAM_VP9\n",
    "    init_res_matrix(PARAM_VP9[\"crfs\"])\n",
    "else:\n",
    "    print(\"No such an codec\")\n",
    "    exit()\n",
    "\n",
    "min_range_crf = s_cod[\"starting_range\"][0]\n",
    "max_range_crf = s_cod[\"starting_range\"][1]\n",
    "\n",
    "with open(tm_file, 'r') as f:\n",
    "    o_data = json.load(f)\n",
    "    \n",
    "#add source name and results matrix\n",
    "o_data[\"content\"] = source_name\n",
    "o_data[\"codec\"] = codec\n",
    "o_data[\"width\"] = raw_width\n",
    "o_data[\"height\"] = raw_height\n",
    "o_data[\"fps\"] = raw_fps\n",
    "o_data[\"shots\"][0][\"assessment\"] = str_matrix\n",
    "    \n",
    "#add emplty target points\n",
    "base_point = o_data[\"shots\"][0][\"opt_points\"][0]\n",
    "for t_name in target_list:\n",
    "    for t_val in target_list[t_name]:\n",
    "        base_point[\"metric\"] = t_name\n",
    "        base_point[\"target\"] = t_val\n",
    "        struct_points.append(base_point.copy())\n",
    "o_data[\"shots\"][0][\"opt_points\"] = struct_points\n",
    "    \n",
    "#add empty shots\n",
    "base_shot = o_data[\"shots\"][0]\n",
    "for i in range(0, num_scenes):\n",
    "    base_shot[\"index\"] = i #assign index to shots in json file\n",
    "    struct_shots.append(base_shot.copy())\n",
    "o_data[\"shots\"] = struct_shots\n",
    "\n",
    "with open(rd_file, 'w') as w:\n",
    "    json.dump(o_data, w, separators=(',',': '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd13ccc",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "Find the shot encoded to a certain crf that has the closest quality or rate to the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8c9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(s,i,c):\n",
    "    add_info = s_cod[\"add_param\"]\n",
    "    lib = s_cod[\"lib\"]\n",
    "    o = DIST_PATH + str(i) + \"/\" + str(c) + \"_\" + codec.upper() + \".\" + s_cod[\"container\"]\n",
    "    enc = f\"ffmpeg -f rawvideo -video_size {raw_width}x{raw_height} -r {raw_fps} \\\n",
    "        -pixel_format yuv420p -i {REF_PATH + s} -c:v {lib} -crf {c} {add_info} {o} -hide_banner -loglevel error\"\n",
    "    subprocess.call(enc, shell=True)\n",
    "    return o\n",
    "\n",
    "def assess(s,o):\n",
    "    c_vmaf = f\"ffmpeg -f rawvideo -r {raw_fps} -video_size {raw_width}x{raw_height} -i {REF_PATH + s} \\\n",
    "            -i {o} -hide_banner -loglevel error\\\n",
    "            -lavfi \\\"[0:v]setpts=PTS-STARTPTS[ref];\\\n",
    "                    [1:v]scale={raw_width}x{raw_height}:flags=bicubic, setpts=PTS-STARTPTS[dist];\\\n",
    "                    [dist][ref]libvmaf=feature=name=psnr:log_path={VMAF_LOGS}:log_fmt=json\\\" \\\n",
    "            -f null -\" #|name=float_ssim|name=float_ms_ssim to compute the other metrics\n",
    "    subprocess.call(c_vmaf, shell=True)\n",
    "\n",
    "#store the quality and rate results for each shot at each encoded crf\n",
    "def store_results(i,c,o):\n",
    "    with open(VMAF_LOGS, 'r') as r: #extract quality and rate values\n",
    "        i_data = json.load(r)\n",
    "    o_data[\"shots\"][i][\"assessment\"][\"crf\"][c] = c\n",
    "    o_data[\"shots\"][i][\"assessment\"][\"vmaf\"][c] = i_data[\"pooled_metrics\"][\"vmaf\"][\"mean\"]\n",
    "    o_data[\"shots\"][i][\"assessment\"][\"psnr\"][c] = (6*i_data[\"pooled_metrics\"][\"psnr_y\"][\"mean\"] + \\\n",
    "        i_data[\"pooled_metrics\"][\"psnr_cb\"][\"mean\"] + i_data[\"pooled_metrics\"][\"psnr_cr\"][\"mean\"])/8\n",
    "    info = f\"ffprobe -v error -select_streams v:0 -show_entries format:stream -print_format json {o}\"\n",
    "    cout = json.loads(subprocess.run(info.split(), stdout=subprocess.PIPE, stderr=subprocess.STDOUT).stdout)\n",
    "    o_data[\"shots\"][i][\"assessment\"][\"rate\"][c] = int(cout[\"format\"][\"bit_rate\"])\n",
    "    o_data[\"shots\"][i][\"duration\"] = float(cout[\"format\"][\"duration\"])\n",
    "    \n",
    "def save_opt(i, t, opt):\n",
    "    o_data[\"shots\"][i][\"opt_points\"][t][\"crf\"] = int(opt)\n",
    "    with open(rd_file, 'w') as w:\n",
    "        json.dump(o_data, w, separators=(',',': '))\n",
    "    \n",
    "def search_opt(t_name, t_val, sx_end, dx_end, i_sx_end, i_dx_end):\n",
    "    if t_val < sx_end and t_val > dx_end: #if the target is in the range\n",
    "        n = interpolate(i_sx_end, i_dx_end)\n",
    "    elif t_val > sx_end: #if the target is out of the range in the left side\n",
    "        n = 0 #if no other points in this direction had been stored encode at the min crf\n",
    "        i = i_sx_end - 1\n",
    "        while n == 0 and i>= 0:\n",
    "        #the first point you find is the new lower end of the range\n",
    "            if not res_matrix[t_name][i] == 0:\n",
    "                n = interpolate(i, i_sx_end)\n",
    "            i -= 1\n",
    "    elif t_val < dx_end: #if the target is out of the range in the right side\n",
    "        n = s_cod[\"crfs\"]-1 #if there's no other points, encode at the max crf\n",
    "        i = i_dx_end + 1\n",
    "        while n == s_cod[\"crfs\"]-1 and i <= s_cod[\"crfs\"]-1:\n",
    "            #the first point you find is the new upper end of the range\n",
    "            if not res_matrix[t_name][i] == 0:\n",
    "                n = interpolate(i_dx_end, i)\n",
    "            i += 1\n",
    "    return n\n",
    "\n",
    "#linear interpolation of the target and the weight alpha between sx and dx\n",
    "def interpolate(sx, dx):\n",
    "    alpha = (res_matrix[t_name][sx] - t_val) / (res_matrix[t_name][sx] - res_matrix[t_name][dx])\n",
    "    new_point = round(res_matrix[\"crf\"][sx] - alpha * (res_matrix[\"crf\"][sx] - res_matrix[\"crf\"][dx]))\n",
    "    return new_point\n",
    "\n",
    "#proportion to find tuned target between t and s slopes\n",
    "def compute_target(t, s):\n",
    "    new_target = t_val * s / t\n",
    "    return new_target\n",
    "\n",
    "def combine():\n",
    "    min_rate = math.inf\n",
    "    min_dist = 100\n",
    "    o = []\n",
    "    for comb in itertools.product(*s_crfs): #for each combination\n",
    "        dist = 0\n",
    "        rate = 0\n",
    "        for i,v in enumerate(comb):\n",
    "            dist = dist + (100 - o_data[\"shots\"][i][\"assessment\"][\"vmaf\"][v]) * o_data[\"shots\"][i][\"duration\"]\n",
    "            rate = rate + o_data[\"shots\"][i][\"assessment\"][\"rate\"][v] * o_data[\"shots\"][i][\"duration\"]\n",
    "        dist = dist / duration\n",
    "        rate = rate / duration\n",
    "        if t_name == \"vmaf\":\n",
    "            if dist < t_val and rate < min_rate:\n",
    "                min_rate = rate\n",
    "                o = list(comb)\n",
    "        elif t_name == \"rate\":\n",
    "            if rate < t_val and dist < min_dist:\n",
    "                min_dist = dist\n",
    "                o = list(comb)\n",
    "        else:\n",
    "            print(\"ERROR - not a target\")\n",
    "            exit()\n",
    "    return o\n",
    "\n",
    "def compute_slope(xl,yl,xr,yr):\n",
    "    return -(yl-yr)/(xl-xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6515097",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_index = 0\n",
    "point_index = 0\n",
    "for t_name in target_list:\n",
    "    for t_val in target_list[t_name]:\n",
    "        \n",
    "        if opt_tech == \"fs\": #full search\n",
    "            shot_index = 0\n",
    "            if target_index == 0:\n",
    "                s_crfs = np.zeros(shape=(num_scenes, max_range_crf-min_range_crf), dtype=int) #init structure\n",
    "                for shot in sorted(os.listdir(REF_PATH)): #for each shot\n",
    "                    for current_crf in range(min_range_crf, max_range_crf):\n",
    "                        out = encode(shot, shot_index, current_crf) #encoding\n",
    "                        assess(shot, out) #quality assessment\n",
    "                        store_results(shot_index, current_crf, out)\n",
    "                    s_crfs[shot_index] = [c for c in o_data[\"shots\"][i][\"assessment\"][\"crf\"] if c != 0] #take only encoded shots\n",
    "                    shot_index += 1\n",
    "            opt_crfs = combine() #create all combinations\n",
    "            print(opt_crfs)\n",
    "            for i in range(0,num_scenes): #save the opt crf for each shot\n",
    "                save_opt(i, target_index, opt_crfs[i])\n",
    "            \n",
    "        elif opt_tech == \"tg\": #lagrange with target tuning\n",
    "            t_intvl = [np.zeros((2,num_scenes)), np.zeros((2,num_scenes))] # t_ext[max min] ; t_ext[0][rate dist]\n",
    "            s_intvl = np.zeros((2,num_scenes)) # [rate dist]\n",
    "            t_ext = {\"l\": [], \"r\": [], \"slope\": 0.0}\n",
    "            s_ext = {\"l\": [], \"r\": [], \"slope\": 0.0}\n",
    "            t_pts = np.zeros((2,num_scenes), dtype=int) # t_pts[max min]\n",
    "            s_pts = np.zeros(num_scenes, dtype=int)\n",
    "            \n",
    "            if point_index == 0: #if there are no points (first loop)\n",
    "                shot_index = 0\n",
    "                for shot in sorted(os.listdir(REF_PATH)): #for each shot\n",
    "                    out = encode(shot, shot_index, max_range_crf) #encoding\n",
    "                    assess(shot, out) #quality assessment\n",
    "                    store_results(shot_index, max_range_crf, out)\n",
    "                    r = o_data[\"shots\"][shot_index][\"assessment\"][\"rate\"][max_range_crf]\n",
    "                    d = 100 - o_data[\"shots\"][shot_index][\"assessment\"][\"vmaf\"][max_range_crf]\n",
    "                    t_pts[0][shot_index] = max_range_crf\n",
    "                    t_intvl[0][0, shot_index] = r * o_data[\"shots\"][shot_index][\"duration\"] / duration\n",
    "                    t_intvl[0][1, shot_index] = d * o_data[\"shots\"][shot_index][\"duration\"] / duration\n",
    "                    shot_index += 1\n",
    "                t_ext[\"l\"] = np.einsum('ij->i',t_intvl[0])\n",
    "                point_index += 1\n",
    "            if point_index == 1: #if there are no points to compare (second loop)\n",
    "                shot_index = 0\n",
    "                for shot in sorted(os.listdir(REF_PATH)): #for each shot\n",
    "                    out = encode(shot, shot_index, min_range_crf) #encoding\n",
    "                    assess(shot, out) #quality assessment\n",
    "                    store_results(shot_index, min_range_crf, out)\n",
    "                    r = o_data[\"shots\"][shot_index][\"assessment\"][\"rate\"][min_range_crf]\n",
    "                    d = 100 - o_data[\"shots\"][shot_index][\"assessment\"][\"vmaf\"][min_range_crf]\n",
    "                    t_pts[1][shot_index] = min_range_crf\n",
    "                    t_intvl[1][0, shot_index] = r * o_data[\"shots\"][shot_index][\"duration\"] / duration\n",
    "                    t_intvl[1][1, shot_index] = d * o_data[\"shots\"][shot_index][\"duration\"] / duration\n",
    "                    shot_index += 1\n",
    "                t_ext[\"r\"] = np.einsum('ij->i',t_intvl[1])\n",
    "                t_ext[\"slope\"] = compute_slope(t_ext[\"l\"][0],t_ext[\"l\"][1],t_ext[\"r\"][0],t_ext[\"r\"][1])\n",
    "                print(str(\"%.2f\" % t_ext[\"l\"][0])+\" , \"+str(\"%.2f\" % t_ext[\"l\"][1])+\" , \"+str(\"%.2f\" % t_ext[\"r\"][0])+\" , \"+str(\"%.2f\" % t_ext[\"r\"][1]))\n",
    "                print(\"t-slope: \"+str(\"%.16f\" % t_ext[\"slope\"]))\n",
    "                point_index += 1\n",
    "            while not np.array_equal(t_pts[0],t_pts[1]):\n",
    "                shot_index = 0\n",
    "                for shot in sorted(os.listdir(REF_PATH)): #for each shot\n",
    "                    res_matrix = o_data[\"shots\"][shot_index][\"assessment\"]\n",
    "                    current_point = None\n",
    "                    new_point = max_range_crf\n",
    "\n",
    "                    res_matrix[t_name] = [np.inf if item == 0 else item for item in res_matrix[t_name]]\n",
    "                    l = [res_matrix[\"rate\"][t_pts[0][shot_index]],100-res_matrix[\"vmaf\"][t_pts[0][shot_index]]]\n",
    "                    r = [res_matrix[\"rate\"][t_pts[1][shot_index]],100-res_matrix[\"vmaf\"][t_pts[1][shot_index]]]\n",
    "                    s_ext[\"l\"] = np.asarray(l) * o_data[\"shots\"][shot_index][\"duration\"] / duration\n",
    "                    s_ext[\"r\"] = np.asarray(r) * o_data[\"shots\"][shot_index][\"duration\"] / duration\n",
    "                    s_ext[\"slope\"] = compute_slope(s_ext[\"l\"][0],s_ext[\"l\"][1],s_ext[\"r\"][0],s_ext[\"r\"][1])\n",
    "                    print(str(\"%.2f\" % s_ext[\"l\"][0])+\" , \"+str(\"%.2f\" % s_ext[\"l\"][1])+\" , \"+str(\"%.2f\" % s_ext[\"r\"][0])+\" , \"+str(\"%.2f\" % s_ext[\"r\"][1]))\n",
    "                    print(\"s-slope: \"+str(\"%.16f\" % s_ext[\"slope\"]))\n",
    "                    s_target = compute_target(t_ext[\"slope\"], s_ext[\"slope\"])\n",
    "                    print(\"-T\"+str(s_target))\n",
    "                        \n",
    "                    while not current_point == new_point: #if no convergence\n",
    "                        if res_matrix[\"crf\"][new_point] == 0:\n",
    "                            out = encode(shot, shot_index, new_point) #encoding\n",
    "                            assess(shot, out) #quality assessment\n",
    "                            store_results(shot_index, new_point, out)\n",
    "                            \n",
    "                        #element-wise difference between the metric and its target value\n",
    "                        differences = np.asarray(abs(res_matrix[t_name] - s_target))\n",
    "                        i_first_min = np.argmin(differences) #the element with the value closer to the target\n",
    "                        nd_diff = differences.copy()\n",
    "                        nd_diff[i_first_min] = np.inf #replace the minimum with inf\n",
    "                        i_second_min = np.argmin(nd_diff) #find the second minimum\n",
    "                        current_point = i_first_min #the index of the point closer to the target\n",
    "                        \n",
    "                        #swap the values of the two ends if the lower end is bigger than the upper end\n",
    "                        if res_matrix[t_name][i_first_min] > res_matrix[t_name][i_second_min]:\n",
    "                            new_point = search_opt(t_name, s_target, res_matrix[t_name][i_first_min], \\\n",
    "                                        res_matrix[t_name][i_second_min], i_first_min, i_second_min)\n",
    "                        elif res_matrix[t_name][i_first_min] < res_matrix[t_name][i_second_min]:\n",
    "                            new_point = search_opt(t_name, s_target, res_matrix[t_name][i_second_min], \\\n",
    "                                        res_matrix[t_name][i_first_min], i_second_min, i_first_min)\n",
    "                        else: #it may happen that the results are the same ex. black short shots\n",
    "                            current_point = max(i_first_min,i_second_min)\n",
    "                            new_point = current_point\n",
    "                        print(\"np-\"+str(new_point)+\" cp-\"+str(current_point))\n",
    "                    #save current opt points in the list\n",
    "                    r = o_data[\"shots\"][shot_index][\"assessment\"][\"rate\"][current_point]\n",
    "                    d = o_data[\"shots\"][shot_index][\"assessment\"][\"vmaf\"][current_point]\n",
    "                    s_pts[shot_index] = current_point\n",
    "                    s_intvl[0, shot_index] = r * o_data[\"shots\"][shot_index][\"duration\"] / duration\n",
    "                    s_intvl[1, shot_index] = d * o_data[\"shots\"][shot_index][\"duration\"] / duration\n",
    "                    shot_index += 1\n",
    "                #compute rl and compare with rc\n",
    "                current_target = {\"rate\": np.einsum('i->',s_intvl[0]), \"vmaf\": np.einsum('i->',s_intvl[1])} \n",
    "                print(s_intvl)\n",
    "                if current_target[t_name] > t_val:\n",
    "                    t_intvl[0] = s_intvl\n",
    "                    t_pts[0] = s_pts\n",
    "                else:\n",
    "                    t_intvl[1] = s_intvl\n",
    "                    t_pts[1] = s_pts\n",
    "            for i in range(0,num_scenes): #save the opt crf for each shot\n",
    "                save_opt(i, target_index, t_pts[1][i])\n",
    "            print(t_pts[1])\n",
    "        else:\n",
    "            print(\"ERROR - not an opt method\")\n",
    "            exit()\n",
    "        target_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40772a7",
   "metadata": {},
   "source": [
    "## Encode opt video\n",
    "Put together all the individually encoded shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da25b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mux(t_i, t_name, t_val):\n",
    "    file_list = \"\" #list of encoded vids to be stored in OUT_LIST\n",
    "    with open(rd_file, 'r') as f:\n",
    "        o_data = json.load(f)\n",
    "    for shot in range(0,num_scenes):\n",
    "        opt_crf = o_data[\"shots\"][0][\"opt_points\"][t_i][\"crf\"]\n",
    "        file_list = file_list + \"file '\" + DIST_PATH + str(shot) + \"/\" \\\n",
    "        + str(opt_crf) + \"_\" + codec.upper() + \".\" + s_cod[\"container\"] + \"' \\n\"\n",
    "    with open(OUT_LIST, 'w') as w:\n",
    "        w.write(file_list)\n",
    "    o = OUT_PATH+source_name[:9] + \"_\" + t_name + str(t_val) + \"_\" + codec.upper() + \".\" + s_cod[\"container\"]\n",
    "    mux = f\"ffmpeg -f concat -i {OUT_LIST} -c copy {o}\"\n",
    "    subprocess.call(mux, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e978545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_index = 0\n",
    "for t_name in target_list:\n",
    "    for t_val in target_list[t_name]:\n",
    "        mux(target_index, t_name, t_val)\n",
    "        target_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25fd45d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c1646fc",
   "metadata": {},
   "source": [
    "## TODO: Curve fitting\n",
    "When the upper search has tested 3 points, given these 3 RQ points, discover the polynomian or logarithmic function that describes their trend. Repeat this when a new point is computed. Measure the error between the approximation and the actual implementation (lagrangian search above) and assess whether and when it may be useful to speed up the search process, by reducing the number of test to encode before the optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca1475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
